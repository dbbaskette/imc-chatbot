# Cloud Foundry Environment Configuration
# This profile configures the application for CF deployment

# Debug property
imc.chatbot.environment=CF

# CF-specific configurations would go here if needed
# Model configurations are handled by service bindings or environment variables

OPENAI_MODEL: gpt-5-nano
OPENAI_MAX_COMPLETION_TOKENS: 8000


# Local chat model configuration (environment overrides are namespaced to avoid conflict with cloud .env entries)
spring.ai.openai.api-key=${OPENAI_API_KEY:dummy-key}
spring.ai.openai.chat.options.model=${OPENAI_MODEL:qwen/qwen3-4b-2507}

# Conservative parameters for local model compatibility
spring.ai.openai.chat.options.temperature=1
# Limit completion length so smaller local contexts (e.g. llama.cpp/Qwen) don't overflow
spring.ai.openai.chat.options.max_completion_tokens=${OPENAI_MAX_COMPLETION_TOKENS:1024}