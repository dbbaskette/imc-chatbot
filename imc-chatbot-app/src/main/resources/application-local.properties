# Local Environment Configuration
# This profile configures the application for local development

# Debug property
imc.chatbot.environment=LOCAL

# Local chat model configuration (environment overrides are namespaced to avoid conflict with cloud .env entries)
spring.ai.openai.api-key=${LOCAL_OPENAI_API_KEY:dummy-key}
spring.ai.openai.base-url=${LOCAL_OPENAI_BASE_URL:http://127.0.0.1:1234}
spring.ai.openai.chat.options.model=${LOCAL_OPENAI_MODEL:qwen/qwen3-4b-2507}

# Conservative parameters for local model compatibility
spring.ai.openai.chat.options.temperature=1
# Limit completion length so smaller local contexts (e.g. llama.cpp/Qwen) don't overflow
spring.ai.openai.chat.options.max_completion_tokens=${LOCAL_OPENAI_MAX_COMPLETION_TOKENS:1024}
