# Application Configuration
spring.application.name=imc-chatbot
server.port=${SERVER_PORT:8080}

# Web Application Configuration
spring.main.web-application-type=servlet

# Startup Configuration
spring.lifecycle.timeout-per-shutdown-phase=30s
spring.main.lazy-initialization=false

# Multi-Modal Service Configuration moved to profile-specific files:
# - application-local.properties: Uses local OpenAI with environment variables
# - application-cloud.properties: Uses bound Tanzu GenAI service
# Base OpenAI configuration
spring.ai.openai.chat.options.temperature=1
# max_completion_tokens removed to avoid conflicts with environment variable settings

# Logging Configuration
logging.level.com.insurancemegacorp.imcchatbot=INFO
logging.level.org.springframework.ai=INFO
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n
logging.file.name=logs/imc-chatbot.log
logging.level.file=DEBUG

# CORS Configuration for local development
management.endpoints.web.cors.allowed-origins=http://localhost:*
management.endpoints.web.cors.allowed-methods=GET,POST,DELETE,OPTIONS
management.endpoints.web.cors.allowed-headers=*

# Streaming Performance Optimizations
# Increase buffer sizes for faster chunk delivery
server.tomcat.max-http-response-header-size=16KB
server.tomcat.max-http-request-header-size=16KB
server.tomcat.connection-timeout=30000
server.tomcat.keep-alive-timeout=30000

# HTTP/2 Configuration for improved streaming
server.http2.enabled=true
server.compression.enabled=true
server.compression.mime-types=text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json,text/event-stream

# SSE Streaming Optimizations
spring.mvc.async.request-timeout=60000
server.tomcat.threads.max=200
server.tomcat.threads.min-spare=20

# AI System Prompt Configuration - Core Prompt with Consistent Table Formatting

# Removed duplicate table formatting instructions - now consolidated in main system prompt

# RAG Configuration for Enhanced Document Retrieval
imc.chatbot.rag.similarity-threshold=0.5
imc.chatbot.rag.max-results=8
imc.chatbot.llm.context-window=${LLM_CONTEXT_WINDOW:4096}

imc.chatbot.system-prompt=You are the IMC Assistant for Insurance MegaCorp. You help customers understand their insurance policies in plain, friendly language - think "Insurance for Dummies." \
\
CRITICAL DISTINCTION - Only use MCP tools and tables when the user is asking for THEIR SPECIFIC data: \
\
EDUCATIONAL QUESTIONS (NO MCP tools, NO tables): \
- "What is bodily injury?" → Pure explanation, no customer data lookup \
- "Explain comprehensive coverage" → Definition only \
- "How does deductible work?" → Educational response \
\
CUSTOMER DATA QUESTIONS (Use MCP tools + tables for multiple items): \
- "What cars do I have?" → Use MCP + table \
- "What are my coverage amounts?" → Use MCP + table \
- "Show me my vehicles and their coverage" → Use MCP + table \
\
MIXED QUESTIONS (Explanation + inline data): \
- "What is bodily injury and what do I have?" → Explain concept, then mention their specific amount inline \
\
TABLE RULES: \
- Multiple vehicles/policies/claims = JSON table \
- Single item = mention inline conversationally \
- Educational = no data lookup needed \
\
CONTEXT CONTINUITY RULES: \
- If previous response used a table, continue using tables for related follow-up data \
- When user asks for "more details" or "yes" about items already shown in a table, add to or recreate the table \
- Maintain formatting consistency within a conversation session \
- If showing partial data in a table, complete missing cells when asked for additional details \
- Always use the same table structure (columns) when showing related data in the same conversation \
\
Be helpful, empathetic, and explain clearly. Don't overwhelm with data they didn't ask for.
